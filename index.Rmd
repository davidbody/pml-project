---
title: "Practical Machine Learning Course Project"
author: "David W. Body"
date: "August 19, 2015"
output: html_document
---

This is my course project for the Practical Machine Learning course from Coursera and the Johns Hopkins Bloomberg School of Public Health.

This project uses Human Activity Recognition data from a study of weight lifting exercise.

## Background

Details and data are available at [groupware.les.inf.puc-rio.br/har](http://groupware.les.inf.puc-rio.br/har).

Each of six participants performed one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different fashions. In the first (A), each participant performed the curls correctly. In each of the others, the participants did the curls incorrectly: throwing the elbows (B), lifting the dumbbells only halfway (C), lowering the dumbbells only halfway (D), or throwing the hips (E).

The participants were outfitted with sensors on their arms, forearms, and waists, and sensors were also attached to the dumbbells. The goal of this project is to see how well we can predict the manner in which the exercise was performed using the sensor data.

For more information and an analysis of the data, see Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. **Qualitative Activity Recognition of Weight Lifting Exercises**. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013.

## Getting the Data

We download the data from location specified in the project assignment. We also grab the test data for the second part of the project assignment.

```{r, cache=TRUE}
setwd("~/study/machine_learning/project")

if (!file.exists("./data/pml-training.csv")) {
    download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", 
                  destfile="./data/pml-training.csv", 
                  method="libcurl")
}

if (!file.exists("./data/pml-testing.csv")) {
    download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", 
                  destfile="./data/pml-testing.csv", 
                  method="libcurl")
}
```

## Cleaning the data

We start by reading the data into a data frame and looking at it.

```{r, cache=TRUE}
har_data <- read.csv("./data/pml-training.csv", stringsAsFactors = FALSE)
str(har_data)
```

There is a lot of data here!

Several variables contain many NA or blank values. I decided not to use any of these variables.

After some exploratory analysis and reading the Velloso, et al. article cited above, I decided to use variables whose names contained the strings "arm", "forearm", "belt", or "dumbbell".

There is a time-series aspect to this data that might be important, and the data contains timestamp variables. However, I decided to see if we could produce a model capable of making accurate predictions ignoring the temporal aspect of the data. (I did this partly because we haven't covered time-series analysis in this course or any of the other courses leading up to in the Data Science Specialization.) As we'll see, it turns out that we can get a pretty accurate predictive model without any time-series analysis for this data.

```{r, cache=TRUE}
any_missing_or_blank <- sapply(har_data, function (x) any(is.na(x) | x == ""))
vars_with_data <- names(har_data[, !any_missing_or_blank])
predictors <- vars_with_data[grep("(fore)?arm|belt|dumbbell", vars_with_data)]
predictors
```

The outcome we want to predict is in the variable "classe", so we create a data frame containing "classe" and our predictors.

```{r, cache=TRUE, warning=FALSE, results='hide'}
library(dplyr)

vars_to_include <- c("classe", predictors)

selected_har_data <- select(har_data, one_of(vars_to_include))
selected_har_data$classe <- as.factor(selected_har_data$classe)
```

## Training the Model

In order to make our results reproducible, we will choose an arbitrary seed for R's random number generator.

```{r}
set.seed(1337)
```

We start by dividing our data in to training and testing sets. Because we have so much data, we'll use 60% of the data for training and 40% for testing.

```{r, cache=TRUE, results="hide"}
library(caret)
```

```{r}
inTrain <- createDataPartition(y = selected_har_data$classe, p = 0.6, list = FALSE)
training <- selected_har_data[inTrain, ]
testing <- selected_har_data[-inTrain, ]

dim(training)
dim(testing)
```

To speed things up, we parallelize training the model across 6 CPU cores.

```{r, cache=TRUE, warning=FALSE, results='hide'}
library(doParallel)
registerDoParallel(cores = 6)
```

We train a Random Forest model using 10-fold cross-validation and 250 trees in each forest.

```{r, cache=TRUE, warning=FALSE}
modFit <- train(classe ~ ., 
                data = training, 
                method = "rf", 
                trControl = trainControl(number = 10), 
                ntree = 250)
```

Examining our final model, we expect our out-of-sample error rate to be about 1%.

```{r, cache=TRUE}
modFit$finalModel
```

## Testing the Model

We then check against the testing data that we set aside earlier and confirm that we do indeed achieve an accuracy of about 99%.

```{r, cache=TRUE}
predictions <- predict(modFit, newdata = testing)
confusionMatrix(data = predictions, testing$classe)
```

## Model Analysis

Using varImp, which we learned about on Quiz 3, we determine which variables are most important in our model.

```{r, cache=TRUE}
varImp(modFit)
```

To gain some insights into our model, we can plot the top two variables against each other, and color the points based on our outcome variable.

```{r, cache=TRUE}
qplot(roll_belt, yaw_belt, color = classe, data = training)
```

The plot shows a pretty tight grouping of outcomes, but with some interesting patterns.

We can also compare our predicted values with the actual values in our testing data.

```{r, cache=TRUE}
testing$predRight <- predictions == testing$classe
qplot(roll_belt, yaw_belt, color=predRight, data=testing)
```

This plot show which values our model predicted incorrectly in the testing data (predRight = FALSE). These seem about what we would expect based on the grouping of data in the previous plot.
